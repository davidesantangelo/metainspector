{"name":"MetaInspector","tagline":"Ruby gem for web scraping purposes.","body":"# MetaInspector [![Build Status](https://secure.travis-ci.org/jaimeiniesta/metainspector.png)](http://travis-ci.org/jaimeiniesta/metainspector) [![Dependency Status](https://gemnasium.com/jaimeiniesta/metainspector.png)](https://gemnasium.com/jaimeiniesta/metainspector) [![Code Climate](https://codeclimate.com/github/jaimeiniesta/metainspector/badges/gpa.svg)](https://codeclimate.com/github/jaimeiniesta/metainspector)\r\n\r\nMetaInspector is a gem for web scraping purposes.\r\n\r\nYou give it an URL, and it lets you easily get its title, links, images, charset, description, keywords, meta tags...\r\n\r\n## See it in action!\r\n\r\nYou can try MetaInspector live at this little demo: [https://metainspectordemo.herokuapp.com](https://metainspectordemo.herokuapp.com)\r\n\r\n## Changes in 4.4\r\n\r\nThe default headers now include `'Accept-Encoding' => 'identity'` to minimize trouble with servers that respond with malformed compressed responses, [as explained here](https://github.com/lostisland/faraday/issues/337).\r\n\r\n## Changes in 4.3\r\n\r\n* The Document API has been extended with one new method `page.best_title` that returns the longest text available from a selection of candidates.\r\n* `to_hash` now includes `scheme`, `host`, `root_url`, `best_title` and `description`.\r\n\r\n## Changes in 4.2\r\n\r\n* The images API has been extended, with two new methods:\r\n\r\n  * `page.images.owner_suggested` returns the OG or Twitter image, or `nil` if neither are present.\r\n  * `page.images.largest` returns the largest image found in the page. This uses the HTML height and width attributes as well as the [fastimage](https://github.com/sdsykes/fastimage) gem to return the largest image on the page that has a ratio squarer than 1:10 or 10:1. This usually provides a good alternative to the OG or Twitter images if they are not supplied.\r\n\r\n* The criteria for `page.images.best` has changed slightly, we'll now return the largest image instead of the first image if no owner-suggested image is found.\r\n\r\n## Changes in 4.1\r\n\r\n* Introduces the `:normalize_url` option, which allows to disable URL normalization.\r\n\r\n## Changes in 4.0\r\n\r\n* The links API has been changed, now instead of `page.links`, `page.internal_links` and `page.external_links` we have:\r\n\r\n```ruby\r\npage.links.raw      # Returns all links found, unprocessed\r\npage.links.all      # Returns all links found, unrelavitized and absolutified\r\npage.links.http     # Returns all HTTP links found\r\npage.links.non_http # Returns all non-HTTP links found\r\npage.links.internal # Returns all internal HTTP links found\r\npage.links.external # Returns all external HTTP links found\r\n```\r\n\r\n* The images API has been changed, now instead of `page.image` we have `page.images.best`, and instead of `page.favicon` we have `page.images.favicon`.\r\n\r\n* Now `page.image` will return the first image in `page.images` if no OG or Twitter image found, instead of returning `nil`.\r\n\r\n* You can now specify 2 different timeouts, `connection_timeout` and `read_timeout`, instead of the previous single `timeout`.\r\n\r\n## Changes in 3.0\r\n\r\n* The redirect API has been changed, now the `:allow_redirections` option will expect only a boolean, which by default is `true`. That is, no more specifying `:safe`, `:unsafe` or `:all`.\r\n* We've dropped support for Ruby < 2.\r\n\r\nAlso, we've introduced a new feature:\r\n\r\n* Persist cookies across redirects. Now MetaInspector will include the received cookies when following redirects. This fixes some cases where a redirect would fail, sometimes caught in a redirection loop.\r\n\r\n## Installation\r\n\r\nInstall the gem from RubyGems:\r\n\r\n```bash\r\ngem install metainspector\r\n```\r\n\r\nIf you're using it on a Rails application, just add it to your Gemfile and run `bundle install`\r\n\r\n```ruby\r\ngem 'metainspector'\r\n```\r\n\r\nThis gem is tested on Ruby versions 2.0.0 and 2.1.3.\r\n\r\n## Usage\r\n\r\nInitialize a MetaInspector instance for an URL, like this:\r\n\r\n```ruby\r\npage = MetaInspector.new('http://sitevalidator.com')\r\n```\r\n\r\nIf you don't include the scheme on the URL, http:// will be used by default:\r\n\r\n```ruby\r\npage = MetaInspector.new('sitevalidator.com')\r\n```\r\n\r\nYou can also include the html which will be used as the document to scrape:\r\n\r\n```ruby\r\npage = MetaInspector.new(\"http://sitevalidator.com\", :document => \"<html><head><title>Hello From Passed Html</title><a href='/hello'>Hello link</a></head><body></body></html>\")\r\n```\r\n\r\n## Accessing response status and headers\r\n\r\nYou can check the status and headers from the response like this:\r\n\r\n```ruby\r\npage.response.status  # 200\r\npage.response.headers # { \"server\"=>\"nginx\", \"content-type\"=>\"text/html; charset=utf-8\", \"cache-control\"=>\"must-revalidate, private, max-age=0\", ... }\r\n```\r\n\r\n## Accessing scraped data\r\n\r\nYou can see the scraped data like this:\r\n\r\n```ruby\r\npage.url                 # URL of the page\r\npage.scheme              # Scheme of the page (http, https)\r\npage.host                # Hostname of the page (like, sitevalidator.com, without the scheme)\r\npage.root_url            # Root url (scheme + host, like http://sitevalidator.com/)\r\npage.title               # title of the page from the head section, as string\r\npage.best_title          # best title of the page, from a selection of candidates\r\npage.links.raw           # every link found, unprocessed\r\npage.links.all           # every link found on the page as an absolute URL\r\npage.links.http          # every HTTP link found\r\npage.links.non_http      # every non-HTTP link found\r\npage.links.internal      # every internal link found on the page as an absolute URL\r\npage.links.external      # every external link found on the page as an absolute URL\r\npage.meta['keywords']    # meta keywords, as string\r\npage.meta['description'] # meta description, as string\r\npage.description         # returns the meta description, or the first long paragraph if no meta description is found\r\npage.images              # enumerable collection, with every img found on the page as an absolute URL\r\npage.images.best         # Most relevant image, if defined with the og:image or twitter:image metatags. Fallback to the first page.images array element\r\npage.images.favicon      # absolute URL to the favicon\r\npage.feed                # Get rss or atom links in meta data fields as array\r\npage.charset             # UTF-8\r\npage.content_type        # content-type returned by the server when the url was requested\r\n```\r\n\r\n## Meta tags\r\n\r\nWhen it comes to meta tags, you have several options:\r\n\r\n```ruby\r\npage.meta_tags  # Gives you all the meta tags by type:\r\n                # (meta name, meta http-equiv, meta property and meta charset)\r\n                # As meta tags can be repeated (in the case of 'og:image', for example),\r\n                # the values returned will be arrays\r\n                #\r\n                # For example:\r\n                #\r\n                # {\r\n                    'name' => {\r\n                                'keywords'       => ['one, two, three'],\r\n                                'description'    => ['the description'],\r\n                                'author'         => ['Joe Sample'],\r\n                                'robots'         => ['index,follow'],\r\n                                'revisit'        => ['15 days'],\r\n                                'dc.date.issued' => ['2011-09-15']\r\n                              },\r\n\r\n                    'http-equiv' => {\r\n                                        'content-type'        => ['text/html; charset=UTF-8'],\r\n                                        'content-style-type'  => ['text/css']\r\n                                    },\r\n\r\n                    'property' => {\r\n                                    'og:title'        => ['An OG title'],\r\n                                    'og:type'         => ['website'],\r\n                                    'og:url'          => ['http://example.com/meta-tags'],\r\n                                    'og:image'        => ['http://example.com/rock.jpg',\r\n                                                          'http://example.com/rock2.jpg',\r\n                                                          'http://example.com/rock3.jpg'],\r\n                                    'og:image:width'  => ['300'],\r\n                                    'og:image:height' => ['300', '1000']\r\n                                   },\r\n\r\n                    'charset' => ['UTF-8']\r\n                  }\r\n```\r\n\r\nAs this method returns a hash, you can also take only the key that you need, like in:\r\n\r\n```ruby\r\npage.meta_tags['property']  # Returns:\r\n                            # {\r\n                            #   'og:title'        => ['An OG title'],\r\n                            #   'og:type'         => ['website'],\r\n                            #   'og:url'          => ['http://example.com/meta-tags'],\r\n                            #   'og:image'        => ['http://example.com/rock.jpg',\r\n                            #                         'http://example.com/rock2.jpg',\r\n                            #                         'http://example.com/rock3.jpg'],\r\n                            #   'og:image:width'  => ['300'],\r\n                            #   'og:image:height' => ['300', '1000']\r\n                            # }\r\n```\r\n\r\nIn most cases you will only be interested in the first occurrence of a meta tag, so you can\r\nuse the singular form of that method:\r\n\r\n```ruby\r\npage.meta_tag['name']   # Returns:\r\n                        # {\r\n                        #   'keywords'       => 'one, two, three',\r\n                        #   'description'    => 'the description',\r\n                        #   'author'         => 'Joe Sample',\r\n                        #   'robots'         => 'index,follow',\r\n                        #   'revisit'        => '15 days',\r\n                        #   'dc.date.issued' => '2011-09-15'\r\n                        # }\r\n```\r\n\r\nOr, as this is also a hash:\r\n\r\n```ruby\r\npage.meta_tag['name']['keywords']    # Returns 'one, two, three'\r\n```\r\n\r\nAnd finally, you can use the shorter `meta` method that will merge the different keys so you have\r\na simpler hash:\r\n\r\n```ruby\r\npage.meta   # Returns:\r\n            #\r\n            # {\r\n            #   'keywords'            => 'one, two, three',\r\n            #   'description'         => 'the description',\r\n            #   'author'              => 'Joe Sample',\r\n            #   'robots'              => 'index,follow',\r\n            #   'revisit'             => '15 days',\r\n            #   'dc.date.issued'      => '2011-09-15',\r\n            #   'content-type'        => 'text/html; charset=UTF-8',\r\n            #   'content-style-type'  => 'text/css',\r\n            #   'og:title'            => 'An OG title',\r\n            #   'og:type'             => 'website',\r\n            #   'og:url'              => 'http://example.com/meta-tags',\r\n            #   'og:image'            => 'http://example.com/rock.jpg',\r\n            #   'og:image:width'      => '300',\r\n            #   'og:image:height'     => '300',\r\n            #   'charset'             => 'UTF-8'\r\n            # }\r\n```\r\n\r\nThis way, you can get most meta tags just like that:\r\n\r\n```ruby\r\npage.meta['author']     # Returns \"Joe Sample\"\r\n```\r\n\r\nPlease be aware that all keys are converted to downcase, so it's `'dc.date.issued'` and not `'DC.date.issued'`.\r\n\r\n## Other representations\r\n\r\nYou can also access most of the scraped data as a hash:\r\n\r\n```ruby\r\npage.to_hash    # { \"url\"   => \"http://sitevalidator.com\",\r\n                    \"title\" => \"MarkupValidator :: site-wide markup validation tool\", ... }\r\n```\r\n\r\nThe original document is accessible from:\r\n\r\n```ruby\r\npage.to_s         # A String with the contents of the HTML document\r\n```\r\n\r\nAnd the full scraped document is accessible from:\r\n\r\n```ruby\r\npage.parsed  # Nokogiri doc that you can use it to get any element from the page\r\n```\r\n\r\n## Options\r\n\r\n### Timeout & Retries\r\n\r\nYou can specify 2 different timeouts when requesting a page:\r\n\r\n* `connection_timeout` sets the maximum number of seconds to wait to get a connection to the page.\r\n* `read_timeout` sets the maximum number of seconds to wait to read the page, once connected.\r\n\r\nBoth timeouts default to 20 seconds each.\r\n\r\nYou can also specify the number of `retries`, which defaults to 3.\r\n\r\nFor example, this will time out after 10 seconds waiting for a connection, or after 5 seconds waiting\r\nto read its contents, and will retry 4 times:\r\n\r\n```ruby\r\npage = MetaInspector.new('www.google', :connection_timeout => 10, :read_timeout => 5, :retries => 4)\r\n```\r\n\r\nIf MetaInspector fails to fetch the page after it has exhausted its retries,\r\nit will raise `Faraday::TimeoutError`, which you can rescue in your\r\napplication code.\r\n\r\n```ruby\r\nbegin\r\n  page = MetaInspector.new(url)\r\nrescue Faraday::TimeoutError\r\n  enqueue_for_future_fetch_attempt(url)\r\n  render_simple(url)\r\nelse\r\n  render_rich(page)\r\nend\r\n```\r\n\r\n### Redirections\r\n\r\nBy default, MetaInspector will follow redirects (up to a limit of 10).\r\n\r\nIf you want to disallow redirects, you can do it like this:\r\n\r\n```ruby\r\npage = MetaInspector.new('facebook.com', :allow_redirections => false)\r\n```\r\n\r\n### Headers\r\n\r\nBy default, the following headers are set:\r\n\r\n```ruby\r\n{\r\n  'User-Agent'      => \"MetaInspector/#{MetaInspector::VERSION} (+https://github.com/jaimeiniesta/metainspector)\",\r\n  'Accept-Encoding' => 'identity'\r\n}\r\n```\r\n\r\nThe `Accept-Encoding` is set to `identity` to avoid exceptions being raised on servers that return malformed compressed responses, [as explained here](https://github.com/lostisland/faraday/issues/337).\r\n\r\nIf you want to override the default headers then use the `headers` option:\r\n\r\n```ruby\r\n# Set the User-Agent header\r\npage = MetaInspector.new('example.com', :headers => {'User-Agent' => 'My custom User-Agent'})\r\n```\r\n\r\n### HTML Content Only\r\n\r\nMetaInspector will try to parse all URLs by default. If you want to raise an exception when trying to parse a non-html URL (one that has a content-type different than text/html), you can state it like this:\r\n\r\n```ruby\r\npage = MetaInspector.new('sitevalidator.com', :html_content_only => true)\r\n```\r\n\r\nThis is useful when using MetaInspector on web spidering. Although on the initial URL you'll probably have an HTML URL, following links you may find yourself trying to parse non-html URLs.\r\n\r\n```ruby\r\npage = MetaInspector.new('http://example.com/image.png')\r\npage.content_type  # \"image/png\"\r\npage.description   # will returned a garbled string\r\n\r\npage = MetaInspector.new('http://example.com/image.png', :html_content_only => true)\r\npage.content_type  # \"image/png\"\r\npage.description   # raises an exception\r\n```\r\n\r\n### URL Normalization\r\n\r\nBy default, URLs are normalized using the Addressable gem. For example:\r\n\r\n```ruby\r\n# Normalization will add a default scheme and a trailing slash...\r\npage = MetaInspector.new('sitevalidator.com')\r\npage.url # http://sitevalidator.com/\r\n\r\n# ...and it will also convert international characters\r\npage = MetaInspector.new('http://www.詹姆斯.com')\r\npage.url # http://www.xn--8ws00zhy3a.com/\r\n```\r\n\r\nWhile this is generally useful, it can be [tricky](https://github.com/sporkmonger/addressable/issues/182) [sometimes](https://github.com/sporkmonger/addressable/issues/160).\r\n\r\nYou can disable URL normalization by passing the `normalize_url: false` option.\r\n\r\n### Image downloading\r\n\r\nWhen you ask for the largest image on the page with `page.images.largest`, it will be determined by its height and width attributes on the HTML markup, and also by downloading a small portion of each image using the [fastimage](https://github.com/sdsykes/fastimage) gem. This is really fast as it doesn't download the entire images, normally just the headers of the image files.\r\n\r\nIf you want to disable this, you can specify it like this:\r\n\r\n```ruby\r\npage = MetaInspector.new('http://example.com', download_images: false)\r\n```\r\n\r\n## Exception Handling\r\n\r\nBy default, MetaInspector will raise the exceptions found. We think that this is the safest default: in case the URL you're trying to scrape is unreachable, you should clearly be notified, and treat the exception as needed in your app.\r\n\r\nHowever, if you prefer you can also set the `warn_level: :warn` option, so that exceptions found will just be warned on the standard output, instead of being raised.\r\n\r\nYou can also set the `warn_level: :store` option so that exceptions found will be silenced, and left for you to inspect on `page.exceptions`. You can also ask for `page.ok?`, wich will return `true` if no exceptions are stored.\r\n\r\nYou should avoid using the `:store` option, or use it wisely, as silencing errors can be problematic, it's always better to face the errors and treat them accordingly.\r\n\r\n## Examples\r\n\r\nYou can find some sample scripts on the `examples` folder, including a basic scraping and a spider that will follow external links using a queue. What follows is an example of use from irb:\r\n\r\n```ruby\r\n$ irb\r\n>> require 'metainspector'\r\n=> true\r\n\r\n>> page = MetaInspector.new('http://sitevalidator.com')\r\n=> #<MetaInspector:0x11330c0 @url=\"http://sitevalidator.com\">\r\n\r\n>> page.title\r\n=> \"MarkupValidator :: site-wide markup validation tool\"\r\n\r\n>> page.meta['description']\r\n=> \"Site-wide markup validation tool. Validate the markup of your whole site with just one click.\"\r\n\r\n>> page.meta['keywords']\r\n=> \"html, markup, validation, validator, tool, w3c, development, standards, free\"\r\n\r\n>> page.links.size\r\n=> 15\r\n\r\n>> page.links[4]\r\n=> \"/plans-and-pricing\"\r\n```\r\n\r\n## Contributing guidelines\r\n\r\nYou're more than welcome to fork this project and send pull requests. Just remember to:\r\n\r\n* Create a topic branch for your changes.\r\n* Add specs.\r\n* Keep your fake responses as small as possible. For each change in `spec/fixtures`, a comment should be included explaining why it's needed.\r\n* Update `version.rb`, following the [semantic versioning convention](http://semver.org/).\r\n* Update `README.md` if needed (for example, when you're adding or changing a feature).\r\n\r\nThanks to all the contributors:\r\n\r\n[https://github.com/jaimeiniesta/metainspector/graphs/contributors](https://github.com/jaimeiniesta/metainspector/graphs/contributors)\r\n\r\nYou can also come to chat with us on our [Gitter room](https://gitter.im/jaimeiniesta/metainspector) and [Google group](https://groups.google.com/forum/#!forum/metainspector).\r\n\r\n## Related projects\r\n\r\n* [go-metainspector](https://github.com/fern4lvarez/go-metainspector), a port of MetaInspector for Go.\r\n* [Node-MetaInspector](https://github.com/gabceb/node-metainspector), a port of MetaInspector for Node.\r\n\r\n## License\r\nMetaInspector is released under the [MIT license](MIT-LICENSE).\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}